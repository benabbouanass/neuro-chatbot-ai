"""Orchestrateur ultime avec r√©ponses professionnelles am√©lior√©es"""

import requests
import json
import re
from typing import Dict, Any
from utils.config import HUGGINGFACE_API_KEY
from enhanced_styles import get_animated_emoji, get_style_prefix

class UltimateOrchestrator:
    """Orchestrateur avec r√©ponses professionnelles et flexibles"""
    
    def __init__(self):
        self.api_key = "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"
        self.url = "https://openrouter.ai/api/v1/chat/completions"
        self.model = "meta-llama/llama-3.2-3b-instruct:free"
        self.hf_key = HUGGINGFACE_API_KEY
    
    def get_professional_system_prompt(self):
        """Prompt syst√®me professionnel et flexible"""
        return """Tu es Neuro, un assistant IA professionnel et expert en communication adaptative.

MISSION PRINCIPALE:
- R√©pondre de mani√®re professionnelle √† TOUTES les questions
- Adapter ton style selon le contexte d√©tect√©
- Rester courtois m√™me pour les questions hors-sujet
- Toujours orienter vers une solution ou aide

R√àGLES DE COMMUNICATION:
1. PROFESSIONNALISME: Toujours poli, respectueux et constructif
2. FLEXIBILIT√â: Adapter le ton selon le style d√©tect√© (press√©, poli, etc.)
3. UTILIT√â: M√™me hors-sujet, apporter de la valeur
4. BRI√àVET√â: R√©ponses concises mais compl√®tes (max 150 mots)

GESTION DES SUJETS:
- Questions techniques ‚Üí Aide professionnelle
- Questions personnelles ‚Üí R√©ponse empathique + redirection
- Questions complexes ‚Üí D√©composition claire
- Erreurs/probl√®mes ‚Üí Solutions pratiques
- Hors-sujet ‚Üí R√©ponse polie + proposition d'aide

STYLES D'ADAPTATION:
- Press√© ‚Üí R√©ponse directe et efficace
- Poli ‚Üí R√©ponse courtoise et d√©taill√©e  
- Autoritaire ‚Üí R√©ponse respectueuse mais ferme
- R√©fl√©chi ‚Üí R√©ponse patiente et explicative
- Cordial ‚Üí R√©ponse chaleureuse et accueillante

Tu es un professionnel qui sait s'adapter √† chaque situation."""

    def get_enhanced_response(self, user_input: str, emotion: str, lead_type: str, style: str, style_emoji: str) -> str:
        """G√©n√®re une r√©ponse dynamique via l'API"""
        
        # Pr√©fixes comportementaux
        prefixes = {
            "press√©": f"Je sens votre urgence {style_emoji}",
            "autoritaire": f"Je respecte votre d√©termination {style_emoji}",
            "poli": f"J'appr√©cie votre courtoisie {style_emoji}",
            "r√©fl√©chi": f"Je vois que vous r√©fl√©chissez {style_emoji}",
            "enthousiaste": f"J'aime votre √©nergie {style_emoji}",
            "√©nergique": f"Votre dynamisme me motive {style_emoji}",
            "concis": f"J'appr√©cie votre approche directe {style_emoji}",
            "cordial": f"Ravi de vous rencontrer {style_emoji}",
            "approbateur": f"Parfait, merci {style_emoji}",
            "neutre": f"Je suis √† votre √©coute {style_emoji}"
        }
        
        prefix = prefixes.get(style, f"Je note votre message {style_emoji}")
        
        # Contexte commercial selon le type de lead
        lead_context = {
            "Hot": "Le client veut ACHETER. Sois direct, propose des solutions imm√©diates, des prix, des actions concr√®tes.",
            "Warm": "Le client est INT√âRESS√â. Qualifie ses besoins, pose des questions intelligentes, nourris son int√©r√™t.",
            "Cold": "Le client REFUSE ou est distant. Reste poli, professionnel, laisse la porte ouverte.",
            "Interested": "Le client H√âSITE. Rassure-le, donne des b√©n√©fices concrets, sans pression.",
            "Unqualified": "Statut IND√âTERMIN√â. Qualifie ses besoins, d√©couvre ses d√©fis, propose ton aide."
        }
        
        # Prompt utilisateur dynamique et sp√©cifique
        user_prompt = f"""CONTEXTE CLIENT:
- Message: "{user_input}"
- Style d√©tect√©: {style} 
- Type de lead: {lead_type}
- √âmotion: {emotion}

INSTRUCTION:
{lead_context.get(lead_type, lead_context["Unqualified"])}

R√âPONSE REQUISE:
Commence OBLIGATOIREMENT par: "{prefix} ‚Äî"
Puis r√©ponds de mani√®re naturelle, commerciale et adapt√©e au style {style}.

Exemples selon le message:
- "Pouvez-vous me pr√©parer le produit ? J'arrive" ‚Üí R√©ponse urgente avec action imm√©diate
- "J'ai besoin d'infos sur le marketing digital" ‚Üí R√©ponse experte avec questions qualifiantes

Sois un vrai assistant commercial dynamique et personnalis√© !"""
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": self.get_dynamic_system_prompt()},
                {"role": "user", "content": user_prompt}
            ],
            "max_tokens": 150,
            "temperature": 0.8,
            "top_p": 0.9
        }
        
        try:
            response = requests.post(url=self.url, headers=headers, data=json.dumps(data), timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    bot_response = result["choices"][0]["message"].get("content", "")
                    if bot_response and bot_response.strip():
                        # V√©rifier que la r√©ponse commence par le pr√©fixe
                        if not bot_response.startswith(prefix):
                            bot_response = f"{prefix} ‚Äî {bot_response}"
                        return bot_response.strip()
            
            print(f"‚ö†Ô∏è API Response Error: {response.status_code}")
            return self.get_dynamic_fallback(user_input, lead_type, prefix, style)
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur API: {e}")
            return self.get_dynamic_fallback(user_input, lead_type, prefix, style)
    
    def detect_question_type(self, text: str) -> str:
        """D√©tecte le type de question pour adapter la r√©ponse"""
        text_lower = text.lower()
        
        # Questions techniques
        if any(word in text_lower for word in ["erreur", "bug", "probl√®me", "marche pas", "fonctionne pas", "aide", "comment"]):
            return "technique"
        
        # Questions sur les donn√©es/analytics
        if any(word in text_lower for word in ["donn√©es", "analytics", "statistiques", "graphique", "rapport"]):
            return "analytics"
        
        # Questions complexes
        if any(word in text_lower for word in ["pourquoi", "expliquer", "comprendre", "d√©tailler", "approfondir"]):
            return "complexe"
        
        # Questions personnelles
        if any(word in text_lower for word in ["je suis", "ma vie", "personnel", "priv√©", "famille"]):
            return "personnel"
        
        # Questions de performance
        if any(word in text_lower for word in ["lent", "rapide", "performance", "vitesse", "optimiser"]):
            return "performance"
        
        # Questions commerciales
        if any(word in text_lower for word in ["prix", "co√ªt", "acheter", "vendre", "produit", "service"]):
            return "commercial"
        
        # Salutations/conversation
        if any(word in text_lower for word in ["bonjour", "salut", "hello", "bonsoir", "√ßa va"]):
            return "salutation"
        
        return "general"
    
    def build_contextual_prompt(self, user_input: str, question_type: str, lead_type: str, style: str, prefix: str) -> str:
        """Construit un prompt contextuel selon le type de question"""
        
        base_context = f"Client dit: '{user_input}'\nStyle d√©tect√©: {style}\nType lead: {lead_type}\n"
        
        prompts = {
            "technique": f"{base_context}QUESTION TECHNIQUE: Fournis une aide professionnelle claire. Commence par '{prefix} ‚Äî' puis donne une solution pratique.",
            
            "analytics": f"{base_context}QUESTION ANALYTICS: Explique les donn√©es de mani√®re accessible. Commence par '{prefix} ‚Äî' puis d√©taille les m√©triques.",
            
            "complexe": f"{base_context}QUESTION COMPLEXE: D√©compose la r√©ponse √©tape par √©tape. Commence par '{prefix} ‚Äî' puis structure ta r√©ponse.",
            
            "personnel": f"{base_context}QUESTION PERSONNELLE: R√©ponds avec empathie puis redirige vers ton expertise. Commence par '{prefix} ‚Äî'.",
            
            "performance": f"{base_context}QUESTION PERFORMANCE: Donne des conseils d'optimisation concrets. Commence par '{prefix} ‚Äî'.",
            
            "commercial": f"{base_context}QUESTION COMMERCIALE: Adapte selon le type de lead. Si Hot ‚Üí action imm√©diate, si Warm ‚Üí qualification. Commence par '{prefix} ‚Äî'.",
            
            "salutation": f"{base_context}SALUTATION: R√©ponds chaleureusement et propose ton aide. Commence par '{prefix} ‚Äî'.",
            
            "general": f"{base_context}QUESTION G√âN√âRALE: R√©ponds professionnellement et propose une aide sp√©cifique. Commence par '{prefix} ‚Äî'."
        }
        
        return prompts.get(question_type, prompts["general"])
    
    def get_professional_fallback(self, user_input: str, question_type: str, lead_type: str, prefix: str, style: str) -> str:
        """R√©ponses de secours professionnelles par type"""
        
        fallbacks = {
            "technique": f"{prefix} ‚Äî Je comprends votre probl√®me technique. Pour vous aider efficacement, pouvez-vous me donner plus de d√©tails sur l'erreur rencontr√©e ?",
            
            "analytics": f"{prefix} ‚Äî Excellente question sur les analytics ! Nos donn√©es montrent des insights pr√©cieux sur le comportement client. Souhaitez-vous que je vous explique une m√©trique sp√©cifique ?",
            
            "complexe": f"{prefix} ‚Äî C'est une question int√©ressante qui m√©rite une r√©ponse d√©taill√©e. Permettez-moi de la d√©composer pour vous donner une explication claire et actionnable.",
            
            "personnel": f"{prefix} ‚Äî Je comprends votre situation. Bien que je me concentre sur l'aide professionnelle, je peux vous orienter vers des ressources adapt√©es. Comment puis-je vous assister ?",
            
            "performance": f"{prefix} ‚Äî La performance est cruciale ! Nos syst√®mes sont optimis√©s pour une r√©ponse en moins de 2 secondes. Y a-t-il un aspect sp√©cifique que vous souhaitez am√©liorer ?",
            
            "commercial": self.get_commercial_fallback(lead_type, prefix),
            
            "salutation": f"{prefix} ‚Äî Bonjour ! Je suis ravi de vous rencontrer. Je suis votre assistant IA sp√©cialis√© en analyse comportementale. Comment puis-je vous aider aujourd'hui ?",
            
            "general": f"{prefix} ‚Äî Merci pour votre question. Je suis l√† pour vous accompagner avec expertise et professionnalisme. Que puis-je faire pour vous aider ?"
        }
        
        return fallbacks.get(question_type, fallbacks["general"])
    
    def get_commercial_fallback(self, lead_type: str, prefix: str) -> str:
        """R√©ponses commerciales adapt√©es au type de lead"""
        
        if lead_type == "Hot":
            return f"{prefix} ‚Äî Parfait ! Je sens votre motivation. Nos solutions sont disponibles imm√©diatement : Basic (99‚Ç¨), Pro (199‚Ç¨), Premium (299‚Ç¨). Laquelle correspond √† vos besoins ?"
        elif lead_type == "Warm":
            return f"{prefix} ‚Äî Votre int√©r√™t me fait plaisir ! Pour mieux vous conseiller, dites-moi : quel est votre principal d√©fi actuellement ?"
        elif lead_type == "Cold":
            return f"{prefix} ‚Äî Je respecte votre position. Aucune pression de ma part. Si vos besoins √©voluent, je reste disponible pour vous accompagner."
        else:
            return f"{prefix} ‚Äî Je suis l√† pour vous renseigner sur nos solutions. Que souhaiteriez-vous d√©couvrir en priorit√© ?"
    
    def analyze_speaking_style(self, text: str) -> Dict[str, Any]:
        """Analyse du style de communication (code existant conserv√©)"""
        text_lower = text.lower()
        
        # Logique d'analyse existante...
        urgence_mots = ["urgent", "vite", "rapidement", "imm√©diatement", "maintenant", "tout de suite", "press√©"]
        urgence_score = sum(1 for mot in urgence_mots if mot in text_lower)
        
        politesse_mots = ["s'il vous pla√Æt", "merci", "bonjour", "bonsoir", "excusez-moi", "pardon", "pouvez-vous"]
        politesse_score = sum(1 for mot in politesse_mots if mot in text_lower)
        
        autorite_mots = ["je veux", "donnez-moi", "j'exige", "il faut", "vous devez", "imm√©diatement"]
        autorite_score = sum(1 for mot in autorite_mots if mot in text_lower)
        
        hesitation_mots = ["peut-√™tre", "je pense", "probablement", "√©ventuellement", "pas s√ªr", "j'h√©site"]
        hesitation_score = sum(1 for mot in hesitation_mots if mot in text_lower)
        
        exclamations = text.count('!')
        majuscules = sum(1 for c in text if c.isupper()) / len(text) if text else 0
        emojis = len(re.findall(r'[üòÄ-üôè]', text))
        
        if urgence_score >= 2:
            style = "press√©"
            emoji = "üèÉ‚ôÇÔ∏è"
        elif autorite_score >= 2:
            style = "autoritaire"
            emoji = "üò†"
        elif politesse_score >= 2:
            style = "poli"
            emoji = "üòä"
        elif hesitation_score >= 1:
            style = "r√©fl√©chi"
            emoji = "ü§î"
        elif exclamations > 1 or emojis > 0:
            style = "enthousiaste"
            emoji = "üéâ"
        elif majuscules > 0.3:
            style = "√©nergique"
            emoji = "üí™"
        else:
            if any(word in text_lower for word in ["bonjour", "salut", "hello", "bonsoir"]):
                style = "cordial"
                emoji = "üëã"
            elif any(word in text_lower for word in ["merci", "ok", "d'accord", "tr√®s bien"]):
                style = "approbateur"
                emoji = "üëç"
            elif len(text.split()) <= 3:
                style = "concis"
                emoji = "üí¨"
            else:
                style = "neutre"
                emoji = "üòê"
        
        return {
            "style": style,
            "emoji": emoji,
            "scores": {
                "urgence": urgence_score,
                "politesse": politesse_score,
                "autorite": autorite_score,
                "hesitation": hesitation_score,
                "intensite": exclamations + emojis
            }
        }
    
    def analyze_emotion_hf(self, text: str) -> Dict[str, Any]:
        """Analyse d'√©motion via Hugging Face (code existant)"""
        headers = {}
        if self.hf_key:
            headers["Authorization"] = f"Bearer {self.hf_key}"
        
        try:
            response = requests.post(
                "https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-emotion",
                headers=headers,
                json={"inputs": text},
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                if data and isinstance(data, list) and data[0]:
                    scores = {item["label"].lower(): item["score"] for item in data[0]}
                    top_emotion = max(scores.keys(), key=lambda k: scores[k])
                    return {"emotion": top_emotion, "scores": scores}
            
        except Exception as e:
            print(f"Erreur √©motion: {e}")
        
        return {"emotion": "neutral", "scores": {"neutral": 0.8}}
    
    def classify_lead_ultimate(self, text: str) -> Dict[str, Any]:
        """Classification des leads (code existant conserv√©)"""
        # Code de classification existant...
        text_lower = text.lower()
        
        hot_expressions = [
            "acheter", "commander", "commande", "achat", "payer", "urgent", "maintenant",
            "prix", "co√ªt", "tarif", "budget", "combien", "pr√™t", "d√©cid√©", "je veux"
        ]
        
        warm_expressions = [
            "int√©ress√©", "int√©resse", "information", "d√©tails", "expliquer", "bonjour",
            "produits", "services", "solutions", "en savoir plus", "j'aimerais"
        ]
        
        cold_expressions = [
            "non", "pas int√©ress√©", "stop", "jamais", "refuser", "pas besoin"
        ]
        
        hot_score = sum(3 if expr in ["acheter", "urgent", "prix", "je veux"] else 1 
                       for expr in hot_expressions if expr in text_lower)
        warm_score = sum(3 if expr in ["int√©ress√©", "information"] else 1 
                        for expr in warm_expressions if expr in text_lower)
        cold_score = sum(3 if expr in ["non", "pas int√©ress√©"] else 1 
                        for expr in cold_expressions if expr in text_lower)
        
        if cold_score >= 3:
            return {"lead_type": "Cold", "confidence": min(0.98, 0.8 + cold_score * 0.05)}
        elif hot_score >= 3:
            return {"lead_type": "Hot", "confidence": min(0.95, 0.75 + hot_score * 0.03)}
        elif warm_score >= 2:
            return {"lead_type": "Warm", "confidence": min(0.80, 0.55 + warm_score * 0.05)}
        else:
            return {"lead_type": "Interested", "confidence": 0.6}
    
    def process_message(self, user_input: str) -> Dict[str, Any]:
        """Pipeline complet avec r√©ponses am√©lior√©es"""
        
        print(f"üîÑ Traitement: {user_input}")
        
        # Analyses existantes
        style_data = self.analyze_speaking_style(user_input)
        style = style_data["style"]
        style_emoji = style_data["emoji"]
        
        emotion_data = self.analyze_emotion_hf(user_input)
        emotion = emotion_data["emotion"]
        
        lead_data = self.classify_lead_ultimate(user_input)
        lead_type = lead_data["lead_type"]
        
        # Nouvelle r√©ponse am√©lior√©e
        bot_response = self.get_enhanced_response(user_input, emotion, lead_type, style, style_emoji)
        
        print(f"ü§ñ R√©ponse professionnelle: {bot_response}")
        
        return {
            "bot_response": bot_response,
            "emotion_data": {
                "emotion": emotion,
                "emotion_scores": emotion_data["scores"],
                "sentiment": "neutral",
                "sentiment_scores": {"neutral": 0.8}
            },
            "lead_data": lead_data,
            "style_data": style_data,
            "metadata": {
                "pipeline": "enhanced_professional",
                "model": self.model,
                "status": "success"
            }
        }

# Instance globale
orchestrator = UltimateOrchestrator()